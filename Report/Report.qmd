---
title: "Report"
format: pdf
editor: visual
geometry: margin=1in
code-block-border-left: TRUE
code-block-bg: true
code-line-numbers: false
highlight-style: "breeze"
code-fold: "show"
code overflow: "wrap"
cap-location: "top"
papersize: "a4paper"
page-width: 8
margin-top: 20px
fig-width: 8
fig-height: 6
fig-format: "png"
fig-dpi: 300
fig-align: "center"
fig-cap-location: "bottom"
toc: true
toc-depth: 3
linkcolor: "brown"
header-includes:
   - \usepackage{amsmath, amssymb, setspace}
   - \onehalfspacing
   - \usepackage{etoolbox} 
   - \makeatletter 
   - \preto{\@verbatim}{\topsep=3pt \partopsep=3pt } 
   - \makeatother
---
\pagebreak
# 1.Data Analysis

Our initial data exploration will involve analyzing each column of the dataset to understand its characteristics. We will utilize R's summary function to obtain a statistical overview of each variable.

```{r,eval=TRUE,echo=FALSE}
library(ggplot2)
library(corrplot)
library(ggfortify)
library(tidyverse)
data <- read.csv('MarketingData')
```

```{r,eval=TRUE,echo=TRUE}

head(data)

dim(data)

summary(data)
```

# 1.1 Food Item Analysis

This section delves into the exploration of four food item categories in our dataset: wine, meat, fish, and fruit. We focus on identifying outliers and data distribution within these categories using boxplots.
```{r,eval=TRUE,echo=FALSE}
par(mfrow=c(1,2))
boxplot(data$MntFishProducts,main="No. of fish purchases")
abline(mean(data$MntFishProducts),0,col="red",lwd=3)

boxplot(data$MntFruits,main="No. of fruit purchases")
abline(mean(data$MntFruits),0,col="red",lwd=3)
```
Our analysis revealed a significant presence of outliers in all four food item categories based on the boxplots. The boxes within the plots represent the interquartile range (IQR), encompassing the middle 50% of the data. Values falling outside the whiskers extending from the boxes are considered potential outliers.
**We have made a horizontal red line along mean and which clearly shows that our mean and median differ from each other quite a bit in each food items.**
```{r,eval=TRUE,echo=FALSE}
par(mfrow=c(1,2))
boxplot(data$MntWines,main="No. of wine purchases")
abline(mean(data$MntWines),0,col="red",lwd=3)

boxplot(data$MntMeatProducts,main="No of meat purchases")
abline(mean(data$MntMeatProducts),0,col="red",lwd=3)
par(mfrow=c(1,1))
```
# 1.2 Mosaic Plots and Our Data

In this case, the mosaic plot will depict the proportion of individuals within each education level category (e.g. 2nd cycle, basic, graduation, masters, PhD) segmented by their marital status (e.g., married, single, together, divorced). The size of each rectangle will visually represent the percentage of people in that specific education level and marital status combination.

```{r,eval=TRUE,echo=FALSE}
table(data$Education,data$Marital_Status)
mosaicplot(table(data$Education[data$Marital_Status %in% c("Divorced", "Married","Single","Together")],data$Marital_Status[data$Marital_Status %in% c("Divorced", "Married","Single","Together")]),
           main="Mosaic plot Education vs Marital status",
           xlab = "Qualifications",ylab = "Marital Status",color = c("gold1","seagreen1","peachpuff2","slateblue1"))
```
\newpage

# 1.3 Correlation Plot

## 1.3.1 Plot 1: Correlations Between All Products

This correlation plot reveals a positive correlation (likely depicted by blue color) between all the products, including seats, fruits, wine, meat, fish, and gold. Positive correlation signifies that when the value of one product increases, the values of other products tend to increase as well, and vice versa.

```{r,eval=TRUE,echo=FALSE}
M = cor(data[11:16])
corrplot(M, method = 'number')
```
## 1.3.2 Plot 2: Correlations Between Purchase Sources

This correlation plot examines the relationship between purchase sources, such as web, catalog, store, and potentially others. **We can see a negative correlation between the Number of web visits and (Number of store and catalog purchases) and we can infer from it that tech savvy people prefer less to go physically to stores **

```{r,eval=TRUE,echo=FALSE}
Q = cor(data[17:21])
corrplot(Q,method='number')
```

## 1.4 Scatter plot between premium products

Another analysis is using scatter plot where we can see that the buyers of the premium products of company like sweets and Wines have more income (Black color). And people with less income(Yellow color) didn't buy these products.

```{r,eval=TRUE,echo=FALSE}
ggplot(data[data$Income<1e5,], aes(x = MntWines, y = MntSweetProducts, color=Income,size=NumWebVisitsMonth)) +
  geom_point(alpha=0.5)+ 
  scale_color_gradient(low = "yellow", high = "black", name = "Income")
```

# 2. Principal Component Analysis

The data we have was high dimensional data with multiple columns which led to difficulty in organizing and analyzing the various components. We thus used PCA to reduce the dimensionalty of our data.

First step was to clean and filter out the data which was not required. We removed the categorical variables as they were increasing the complexity of the data. Further, we removed the columns with zero variance and the rows with missing values. Following is the head of the cleaned data:

```{r}
#| echo: false
categorical_columns <- data %>%
  select(where(is.character))
numerical_columns <- data %>%
  select(-all_of(colnames(categorical_columns)))
required_columns <- numerical_columns[, sapply(numerical_columns, function(col) var(col, na.rm = TRUE) != 0)] 
required_columns <- na.omit(required_columns)  

print(head(required_columns, n=5))
```

As we can see, there are 24 columns even after cleaning the data, which shows the high dimensionalty.

Then, we performed PCA which gave the following result:

```{r}
#| echo: false
pc <- prcomp(required_columns, scale. = TRUE) 
summary(pc)  
```

Below is the plot of the PCA analysis and the cumulative variance of the components:

```{r}
#| echo: false

plot(pc)

```

```{r}
#| echo: false

plot(cumsum(pc$sdev^2/sum(pc$sdev^2)))

```

Thus, around 13 components are able to explain 80% variability in the data.

Below is a plot of the relationship between the first two components after PCA.

```{r}
#| echo: false

autoplot(pc, data=required_columns)

```

Thus, with the help of PCA we can reduce the data with 24 columns to upto 13 columns and still explain 80% variability in the data.

