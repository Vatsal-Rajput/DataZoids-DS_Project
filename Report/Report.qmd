---
title: "Report"
format: pdf
editor: visual
geometry: margin=1in
code-block-border-left: TRUE
code-block-bg: true
code-line-numbers: false
highlight-style: "breeze"
code-fold: "show"
code overflow: "wrap"
cap-location: "top"
papersize: "a4paper"
page-width: 8
margin-top: 20px
fig-width: 7
fig-height: 5
fig-format: "png"
fig-dpi: 300
fig-align: "center"
fig-cap-location: "bottom"
toc: true
toc-depth: 3
linkcolor: "brown"
header-includes:
   - \usepackage{amsmath, amssymb, setspace}
   - \onehalfspacing
   - \usepackage{etoolbox} 
   - \makeatletter 
   - \preto{\@verbatim}{\topsep=3pt \partopsep=3pt } 
   - \makeatother
---

\pagebreak

# 1.Data Analysis

Our initial data exploration will involve analyzing each column of the dataset to understand its characteristics. We will utilize R's summary function to obtain a statistical overview of each variable.

```{r,eval=TRUE,echo=FALSE}
library(ggplot2)
library(corrplot)
library(ggfortify)
library(tidyverse)
library(cluster)
library(factoextra)
library(dplyr)
library(lubridate)
library(caret)
data <- read.csv('MarketingData')
```

```{r,eval=TRUE,echo=TRUE}

head(data)

dim(data)

summary(data)
```

# 1.1 Food Item Analysis

This section delves into the exploration of four food item categories in our dataset: wine, meat, fish, and fruit. We focus on identifying outliers and data distribution within these categories using boxplots.

```{r,eval=TRUE,echo=FALSE}
par(mfrow=c(1,2))
boxplot(data$MntFishProducts,main="No. of fish purchases")
abline(mean(data$MntFishProducts),0,col="red",lwd=3)

boxplot(data$MntFruits,main="No. of fruit purchases")
abline(mean(data$MntFruits),0,col="red",lwd=3)
```

Our analysis revealed a significant presence of outliers in all four food item categories based on the boxplots. The boxes within the plots represent the interquartile range (IQR), encompassing the middle 50% of the data. Values falling outside the whiskers extending from the boxes are considered potential outliers. **We have made a horizontal red line along mean and which clearly shows that our mean and median differ from each other quite a bit in each food items.**

```{r,eval=TRUE,echo=FALSE}
par(mfrow=c(1,2))
boxplot(data$MntWines,main="No. of wine purchases")
abline(mean(data$MntWines),0,col="red",lwd=3)

boxplot(data$MntMeatProducts,main="No of meat purchases")
abline(mean(data$MntMeatProducts),0,col="red",lwd=3)
par(mfrow=c(1,1))
```

# 1.2 Mosaic Plots and Our Data

In this case, the mosaic plot will depict the proportion of individuals within each education level category (e.g. 2nd cycle, basic, graduation, masters, PhD) segmented by their marital status (e.g., married, single, together, divorced). The size of each rectangle will visually represent the percentage of people in that specific education level and marital status combination.

```{r,eval=TRUE,echo=FALSE}
table(data$Education,data$Marital_Status)
mosaicplot(table(data$Education[data$Marital_Status %in% c("Divorced", "Married","Single","Together")],data$Marital_Status[data$Marital_Status %in% c("Divorced", "Married","Single","Together")]),
           main="Mosaic plot Education vs Marital status",
           xlab = "Qualifications",ylab = "Marital Status",color = c("gold1","seagreen1","peachpuff2","slateblue1"))
```

\newpage

# 1.3 Correlation Plot

## 1.3.1 Plot 1: Correlations Between All Products

This correlation plot reveals a positive correlation (likely depicted by blue color) between all the products, including seats, fruits, wine, meat, fish, and gold. Positive correlation signifies that when the value of one product increases, the values of other products tend to increase as well, and vice versa.

```{r,eval=TRUE,echo=FALSE}
M = cor(data[11:16])
corrplot(M, method = 'number')
```

## 1.3.2 Plot 2: Correlations Between Purchase Sources

This correlation plot examines the relationship between purchase sources, such as web, catalog, store, and potentially others. **We can see a negative correlation between the Number of web visits and (Number of store and catalog purchases) and we can infer from it that tech savvy people prefer less to go physically to stores**

```{r,eval=TRUE,echo=FALSE}
Q = cor(data[17:21])
corrplot(Q,method='number')
```

# 1.4 Scatter plot between premium products

Another analysis is using scatter plot where we can see that the buyers of the premium products of company like sweets and Wines have more income (Black color). And people with less income(Yellow color) didn't buy these products.

```{r,eval=TRUE,echo=FALSE}
ggplot(data[data$Income<1e5,], aes(x = MntWines, y = MntSweetProducts, color=Income,size=NumWebVisitsMonth)) +
  geom_point(alpha=0.5)+ 
  scale_color_gradient(low = "yellow", high = "black", name = "Income")
```

# 1.5 Amount spend on products (Kid vs No Kid)

his analysis show the total expenditure per customer for different products and with category kid vs no kid. It can be clearly seen that customer who have kids at their home spend more in every product category.

```{r,eval=TRUE,echo=FALSE}
bar.mat <- matrix(0,2,6)
for(i in 0:1){
  for(j in 1:6){
    bar.mat[i+1,j] <- sum(data[data$Kidhome==i,j+10])/sum(data$Kidhome==i)
  }
}
barplot(bar.mat,
        main="Kid vs No Kids", 
        ylab="Total Amount spend per customer", 
        beside=TRUE, 
        names.arg = c("Wines","Fruits","Meat","Fish","Sweet","Gold"),
        col = c("pink","blue")
)

```




# 2. Maximum Likelihood Estimator

Now we tried to estimate our one of the variable NumStorePurchases using MLE. First we saw it's frequency shape using a histogram. And since it's a discrete variable. We assumed that they follow poisson distribution which is a good guess. Then using the optim function we found the best value of lambda. Below bar plot shows the density of our columns and red line shows our MLE.

```{r,eval=TRUE,echo=FALSE}
pois.lik<-function(theta,y){
  logl<- sum(dpois(y,theta,log=TRUE))
  return(-logl)
}

lam <- optim(0.1,pois.lik,y=data$NumStorePurchases,method="BFGS")$par

c <- numeric(14)
for(i in data$NumStorePurchases){
  c[i+1] <- c[i+1]+1
}
c <- c/sum(c)
barplot(c,names.arg = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13))
x <- seq(0,15,1)
lines(x,dpois(x,lam),col="red")
legend("topright", legend = c("Poisson Distribution MLE"), 
       col = c("red"), lty  = 1)

```

We can check the quality of our estimator using the qqplots. Below we have plotted a QQplot of our data wrt data from MLE. And we can see that mostly points lie on the unit slope line from which we can infer that they are similar in distribution. Whereas when we take the parameter of our distribution randomly let's say 10 then the points doesn't lie on the unit slope line

```{r,eval=TRUE,echo=FALSE}
# Creates a qqplot
par(mfrow=c(1,2))
qqplot(rpois(2216,lam),data$NumStorePurchases,xlab = "Theoretical quantiles of Poiss(lam)",ylab="Quantiles of our actual data",main = "Using MLE")
abline(0,1,col="red",lwd=3)
qqplot(rpois(2216,10),data$NumStorePurchases,xlab = "Theoretical quantiles of Poiss(lam)",ylab="Quantiles of our actual data",main = "Random lambda=10")
abline(0,1,col="red",lwd=3)
```

# 3. Principal Component Analysis

The data we have was high dimensional data with multiple columns which led to difficulty in organizing and analyzing the various components. We thus used PCA to reduce the dimensionalty of our data.

First step was to clean and filter out the data which was not required. We removed the categorical variables as they were increasing the complexity of the data. Further, we removed the columns with zero variance and the rows with missing values. Following is the head of the cleaned data:

```{r}
#| echo: false
data <- data %>%mutate(age_at_enroll = year(Dt_Customer) - Year_Birth)
data = data %>% mutate(days_customer_for = as.numeric(difftime(max(Dt_Customer),Dt_Customer, units = "days")))
categorical_columns <- data %>%
  select(where(is.character))
numerical_columns <- data %>%
  select(-all_of(colnames(categorical_columns)))
required_columns <- numerical_columns[, sapply(numerical_columns, function(col) var(col, na.rm = TRUE) != 0)] 
required_columns <- na.omit(required_columns)  

print(head(required_columns, n=5))
```

As we can see, there are 27 columns even after cleaning the data, which shows the high dimensionalty.

Then, we performed PCA which gave the following result:

```{r}
#| echo: false
pc <- prcomp(required_columns, scale. = TRUE) 
summary(pc)  
```

Below is the plot of the PCA analysis and the cumulative variance of the components:

```{r}
#| echo: false

plot(pc)

```

```{r}
#| echo: false

plot(cumsum(pc$sdev^2/sum(pc$sdev^2)))

```

Thus, around 13 components are able to explain 80% variability in the data.

Below is a plot of the relationship between the first two components after PCA.

```{r}
#| echo: false

autoplot(pc, data=required_columns)

```

Thus, with the help of PCA we can reduce the data with 27 columns to upto 13 columns and still explain 80% variability in the data.

# 4. K-Means Clustering

After reducing the dimensionality, we moved on to clustering of the data to segment the customers according to their spending behaviors. For clustering, we considered the first 3 components from the PCA reduction.

We first applied the elbow method to find the optimum number of clusters

```{r}
#| echo: false

reduced_compo <- pc$x[,1:3]
n_data = reduced_compo
fviz_nbclust(n_data, kmeans, method = "wss") +
  labs(title = "Elbow Method", x = "Number of clusters", y = "WCSS")

```

As is evident from the graph, the optimal number of clusters is 4, as after that there is not a significant reduction in the WCSS even when we increase the number of clusters.

```{r}
#| echo: false
kmeans_model <- kmeans(n_data, centers = 4, nstart = 25)
cluster_data <- data.frame(
  cluster = as.factor(kmeans_model$cluster),
  pca_1 = n_data[, 1],
  pca_2 = n_data[, 2]
)
ggplot(cluster_data, aes(x = pca_1, y = pca_2, color = cluster)) +
  geom_point(size = 3) +
  geom_point(data = data.frame(pca_1 = kmeans_model$centers[, 1], pca_2 = kmeans_model$centers[, 2]),
             aes(x = pca_1, y = pca_2), color = "black", size = 5, shape = "x") +
  scale_color_manual(values = c("orange", "green","pink","blue")) +
  labs(title = "Clusters of customers", x = "pca_1", y = "pca_2") +
  theme_minimal()
```

The figure above represents the different clusters of customers based and their relationship with the first and second PCA components.

Below we have a summary of the different characteristics of all the different clusters:

```{r}
#| echo: false

cluster = cluster_data[,1]
final_data = cbind(required_columns,cluster)
final_data = final_data %>% mutate(total_Mnt = MntWines+MntFruits+MntMeatProducts+MntFishProducts+MntSweetProducts+MntGoldProds)
final_data = final_data %>% mutate(num_children = Teenhome+Kidhome)
final_data = final_data %>% mutate(num_total_purchases = NumDealsPurchases+NumWebPurchases+NumCatalogPurchases+NumStorePurchases+NumWebVisitsMonth)
df_no_outliers <- subset(final_data, Income <= 250000)
basic_info <- c('Income', 'num_children', 'Kidhome', 'Teenhome', 'num_total_purchases', 'total_Mnt', 'cluster')
basic_info_summary <- t(aggregate(cbind(Income, num_children, Kidhome, Teenhome, num_total_purchases, total_Mnt) ~ cluster, data = df_no_outliers, FUN = mean))

basic_info_summary = as.data.frame(basic_info_summary)
basic_info_summary
```

# 4.1 Inference on the basis 0f Clusters

## 4.1.1 Plot 1: Income and Spending Patterns

```{r}
#| echo: false
par(mfrow=c(1,3))
p1 <- ggplot(df_no_outliers, aes(x = Income, y = total_Mnt, color = factor(cluster))) +
  geom_point() +
  ggtitle("Income vs Total Spending") + coord_cartesian(xlim =c(0, 160000), ylim = c(0, 2500))

plot(p1)

p2 <- ggplot(df_no_outliers, aes(x = factor(cluster), y = Income, fill = factor(cluster))) + geom_boxplot()+theme(legend.position="none")+
  ggtitle("Income by Cluster")+coord_cartesian( ylim = c(0, 160000))
plot(p2)

p3 <- ggplot(df_no_outliers, aes(x = factor(cluster), y = total_Mnt, fill = factor(cluster))) +
  geom_boxplot()+theme(legend.position="none")+ggtitle("Total Spending by Cluster")+coord_cartesian( ylim = c(0, 2500))
plot(p3)
```

As is evident by the plots:

**Cluster 1**: This cluster is characterised by high income and high spending pattern customers. Their spending ranges from 1000 - 1500 units.

**Cluster 2**: This cluster is characterized by middle income and middle spending pattern customers. They also have a high variability in spending ranging from around 250 - 800 units.

**Cluster 3**: This cluster contains customers with low income and low spending patterns. They have small variability in spending ranging from just around 10 - 100 units.

**Cluster 4**: This cluster is characterized by customers with highest income and highest spending patterns. They also have a large variability in spending patterns ranging from around 1400 - 1900 units.

## 4.1.2 Plot 2: Number of Children

```{R}
#| echo: false
#| warning: false 

library(ggplot2)

p4 <- ggplot(df_no_outliers, aes(x = factor(cluster), fill = factor(num_children))) + geom_bar(position = "dodge")+labs(title = "Count of Clusters by Number of Children")
p5 <- ggplot(df_no_outliers, aes(x = factor(cluster), fill = factor(Kidhome))) + geom_bar(position = "dodge")+labs(title = "Count of Clusters by Kidhome")
p6 <- ggplot(df_no_outliers, aes(x = factor(cluster), fill = factor(Teenhome))) + geom_bar(position = "dodge") + labs(title = "Count of Clusters by Teenhome")


plot(p4)
plot(p5)
plot(p6)


```

Our analysis reveals distinct clusters based on income, spending habits, and the presence of children within each group:

**Cluster 4:** Characterized by highest income and high spending, with fewer children on average (0.13), predominantly having one child.

**Cluster 1:** Represents high-income individuals with moderate spending patterns. This group averages 1.16 children, with a higher proportion of teenagers (0.95) than younger children (0.21).

**Cluster 2:** Comprises individuals with middle income and spending, yet the highest number of children overall. With an average of 1.73 children, this group primarily consists of teenagers (1.02) with fewer younger children (0.71).

**Cluster 3:** Exhibits the lowest income and spending levels, with a moderate number of children (0.81). Notably, most children in this group are teenagers.

Understanding these clusters aids in tailoring marketing strategies and product offerings to better meet the diverse needs of customers across income levels and family demographics.

## 4.1.3 Plot 3: Age Analysis

```{R}
#| echo: false
#| warning: false 

 p1 <- ggplot(df_no_outliers, aes(x = age_at_enroll, color = factor(cluster))) +
  geom_density(kernel = "gaussian", adjust = 2) +
  scale_color_brewer(palette = "Pastel1")
 plot(p1)

```

```{R}
#| echo: false
#| warning: false 

 p2 <- ggplot(df_no_outliers, aes(x = factor(cluster), y = age_at_enroll)) +
  geom_boxplot(aes(color = factor(cluster))) +
  scale_color_brewer(palette = "Pastel1")
plot(p2)

```

The analysis of customer behavior reveals a distinct pattern in income distribution across age groups.
Notably, the youngest age group dominates the highest income bracket, alongside a noteworthy alignment with the lowest income group, which shares a similar average age profile. Conversely, individuals aged 50-55 predominantly occupy the middle income bracket, indicating a peak in earning capacity and career progression for this demographic segment. 
The concentration of mid-life earners within the middle income group suggests a stable income level corresponding to accrued experience and expertise. 
Additionally, the high income group's average age around 50 signifies sustained financial success and stability extending into mid-life stages.

These findings underscore the interplay between age, career trajectory, and economic status, offering valuable insights for targeted marketing strategies and tailored services to cater to diverse customer segments effectively.

## 4.1.4 Plot 4: Spending Pattern on different Products

```{R}
#| echo: false
#| warning: false 


spending_columns <- c('MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds')
spend <- aggregate(. ~ cluster, data = df_no_outliers[, c(spending_columns, 'cluster')], FUN = sum)
spend <- spend[, -which(names(spend) == "cluster")] 
spend_matrix <- as.matrix(spend)


spend_pct_by_category <- prop.table(spend_matrix, 1)

# View the percentage data
View(spend_pct_by_category) 

# Plotting percentage of spending by category and cluster
cluster <- c(rep("1" , 6) , rep("2" , 6) , rep("3" , 6) , rep("4" , 6) )
category <- rep(spending_columns , 4)
spend_pct_by_category = as.numeric(spend_pct_by_category )
spending_data <- data.frame(cluster, category, spend_pct_by_category)

ggplot(spending_data, aes(y = spend_pct_by_category, fill = category, x=cluster)) +
geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Percentage of Spending by Category and Cluster") +
  xlab("Cluster") +
  ylab("Percentage")




```

For food category, we can see that:

The clusters spend on the category pretty much follows their overall spend. Cluster 1 spends the most on food, followed by cluster 2, cluster 3 and cluster 0.

All clusters spend more than wines, followed by meat products.

**Cluster 3 and cluster 1** spend significantly more (over half of their total spend) on wine compared to other categories, then around 20% on meat products

**Cluster 4** spend more balanced than other clusters, this cluster spend more on gold than any other clusters. Interestingly, this cluster and cluster 0 are both lower income and lower spend clusters, but they spend more on gold than other clusters.

**Cluster 2** spend around 45% on wine and 35% on meat products, they spend more than meat than other clusters

## 4.1.5 Plot 5: Purchase Preferences

```{R}
#| echo: false
#| warning: false 

   promotion_list <- c('NumDealsPurchases', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'cluster')
promotion_summary <- aggregate(cbind(NumDealsPurchases, AcceptedCmp1, AcceptedCmp2, AcceptedCmp3, AcceptedCmp4, AcceptedCmp5, Response) ~ cluster, data = df_no_outliers, FUN = sum)
promotion_summary
     
```

```{R}
#| echo: false
#| warning: false 

    p1 <- ggplot(df_no_outliers, aes(x = cluster, y = NumDealsPurchases),color = factor(cluster)) + geom_boxplot()
plot(p1)
     
```

Our analysis indicates that middle-income customers demonstrate the highest inclination towards purchasing discounted products, followed by the lowest income group. Conversely, the highest and high income brackets show less interest in discounted deals. This suggests that discount promotions should primarily target low-income customers to optimize sales opportunities.

```{R}
#| echo: false
#| warning: false 

   p2 <- ggplot(df_no_outliers, aes(x = cluster, y = NumStorePurchases)) + geom_boxplot()
plot(p2)

```

This analysis reveals significant disparities in store purchase behavior across different income clusters:

**High-Income Cluster:** Exhibits the highest frequency of store purchases, indicating a strong preference for in-store shopping among affluent customers.

**Highest and Middle Income Customers:** Display similar levels of store purchases, suggesting that these income groups also favor traditional brick-and-mortar retail experiences.

**Low-Income Customers:** Shows the least preference for store purchases, indicating a potential inclination towards alternative shopping channels or consumption patterns.

```{R}
#| echo: false
#| warning: false 

    p3 <- ggplot(df_no_outliers, aes(x = cluster, y = NumWebPurchases)) + geom_boxplot()
plot(p3)
     
```

**Lowest Income Cluster (Cluster 3):** Displays the lowest frequency of web purchases, indicating limited engagement with online shopping platforms among individuals in this income bracket.

**Middle-Income Cluster:** Shows the highest level of web purchases, suggesting a significant reliance on online channels for shopping among this demographic.

**High and Highest-Income Clusters (Clusters 1 and 4):** Exhibit similar levels of web purchases, indicating comparable engagement with online shopping platforms among these customers.

```{R}
#| echo: false
#| warning: false 

   p4 <- ggplot(df_no_outliers, aes(x = cluster, y = NumCatalogPurchases)) + geom_boxplot()
plot(p4)
```

Catalog purchases are most prevalent among highest-income customers followed by high income customers, indicating a strong preference for this shopping channel. Conversely, individuals in the lowest income bracket show minimal engagement with catalogs and middle income bracket also does not seem to prefer the catalog purchases much but definitely they prefer it more than the lowest income group of customers.

```{R}
#| echo: false
#| warning: false 

 web_visits_by_cluster <- aggregate(NumWebVisitsMonth ~ cluster, data = df_no_outliers, FUN = sum)
web_visits_by_cluster

```

```{R}
#| echo: false
#| warning: false 

  p5 <- ggplot(df_no_outliers, aes(x = cluster, y = NumWebVisitsMonth)) + geom_boxplot()
plot(p5)

```

Web visits are most frequent among the lowest income group, but their conversion to purchases is the lowest. Conversely, high and highest-income individuals visit the web less frequently but exhibit higher purchase conversion rates. This suggests a more purposeful and efficient online shopping behavior among high income segments.

## 4.1.6 Plot 6: Recency Analysis

```{R}
#| echo: false
#| warning: false 

  ggplot(df_no_outliers, aes(x = Recency, fill = factor(cluster))) + geom_histogram(position = "dodge")

```

```{R}
#| echo: false
#| warning: false 

 ggplot(df_no_outliers, aes(x = factor(cluster), y = Recency, fill = factor(cluster))) + geom_boxplot()


```

Recency analysis reveals the highest-income group with the least recent engagements, contrasting with the high-income group, which exhibits the highest recency. Interestingly, the low and middle income clusters show recency levels akin to the high-income group, despite their lower income status. These findings emphasize the need for tailored engagement strategies across income segments to optimize customer retention and satisfaction.

## 4.1.7 Plot 7: Retention Analysis

```{R}
#| echo: false
#| warning: false 

  ggplot(df_no_outliers, aes(x = days_customer_for, fill = factor(cluster))) + geom_density(alpha = 0.5)

```

```{R}
#| echo: false
#| warning: false 

  ggplot(df_no_outliers, aes(x = factor(cluster), y = days_customer_for, fill = factor(cluster))) + geom_bar(stat = "summary", fun = "mean", position = "dodge")

```

Customer retention rates vary across income groups, with highest-income individuals showing the highest retention, followed closely by middle-income customers. Interestingly, both high and lowest income groups exhibit similar, lower retention rates, indicating a propensity for changing preferences among these demographics. Tailored strategies are crucial to enhance loyalty across diverse income segments and maximize long-term customer value.

# 4.2 Conclusion

After conducting data analysis and clustering using K-means, four distinct customer segments emerged with unique characteristics and spending behaviors:

**Cluster 4** - Highest Affluent and Highest Spender:

Family Portrait: Typically childless or with only one child; diverse age distribution. Spending Behavior: Prefers in-store and catalog shopping over online; shows a preference for wine and meat products; less inclined towards discounted items and prefer traditional shopping channels.

**Cluster 1** - High Income and High Spend:

Family Portrait: More likely to have children, especially teenagers. Spending Behavior: Displays a strong affinity for wine purchases and discounts; exhibits higher online spending compared to other clusters showing a balance between online and offline shopping preferences.

**Cluster 2** - Middle Income, Middle Spend:

Family Portrait: Likely to have both young children and teenagers. Spending Behavior: Despite low income, allocates a significant portion of spending to wine; also shows interest in gold products.

**Cluster 3** - Low Income, Low Spend:

Family Portrait: Skews towards families with more young children than teenagers; relatively younger demographic. Spending Behavior: Balanced spending across categories; displays a preference for gold products despite limited overall spending; frequent website visits with low purchase conversion rates. Our analysis illustrates the challenges faced by lower-income families, highlighting their limited spending capacity despite preferences for certain product categories.

Understanding these distinct segments allows businesses to tailor marketing strategies and product offerings to better meet the needs and preferences of each customer group, ultimately enhancing customer satisfaction and engagement.

# 5. Linear Regression

The objective of this analysis is to explore the relationship between amount spent by people on different goods and several marketing and customer-related variables. The dataset used for the analysis contains information on sales, marketing campaign outcomes, customer demographics, and purchasing behavior. By building a linear regression model, we aim to identify the key predictors that influence sales and develop insights for optimizing marketing strategies and improving sales performance.

# 5.1 Methodology

The linear regression analysis follows a standard methodology, including data preprocessing, model building, and evaluation. Predictor variables were selected based on their relevance to sales and underwent scaling to ensure comparability. The dataset was split into training and testing sets using a 80-20 train-test split. A multiple linear regression model was fitted to the training data using ordinary least squares estimation. Model evaluation was performed using MSE and R-squared metrics on the testing set to assess predictive performance.

# 5.2 Feature Selection

```{r pressure, echo=FALSE}

dat <- read.csv('MarketingData')

dat=dat[,-1]

# Combining the required columns

num_purchase=dat$NumDealsPurchases+dat$NumWebPurchases+dat$NumCatalogPurchases+dat$NumStorePurchases
num_child=dat$Kidhome+dat$Teenhome
amt_spent=dat$MntWines+dat$MntFruits+dat$MntMeatProducts+dat$MntFishProducts+dat$MntSweetProducts+dat$MntGoldProds

dat1=cbind(dat[,c(2,5,9,20)],num_purchase,num_child,amt_spent)

#Scaling the Data

dat1=as.data.frame(scale(dat1))

# Train test split

set.seed(123) 

train_index <- createDataPartition(dat1$amt_spent, p = 0.8, list = FALSE)

# Create training and testing sets
train_data <- dat1[train_index, ]
test_data <- dat1[-train_index, ]

# Fitting linear regression model with predictors Year_Birth, Income,
# Recency, NumWebVisitsMonth, num_purchase, num_child

mod1=lm(amt_spent~Year_Birth+Income+Recency+NumWebVisitsMonth+num_purchase+num_child,data=train_data)
summary(mod1)$coefficients

```

According to the p-value, insignificant predictors were dropped, including Year_Birth and Receny.

# 5.3 Results

```{r pressure1, echo=FALSE}


mod2=lm(amt_spent~Income+NumWebVisitsMonth+num_purchase+num_child,data=train_data)


summary(mod2)$coefficients

```

The coefficients of the linear regression model are presented in Table 2. Significant predictors of sales include Income, Number of Web visits,Total number of purchases and number of kids, indicating their impact on sales performance.

# 5.4 Model Performance

```{r pressure2, echo=FALSE}

predictions <- predict(mod2, newdata = test_data)

mse <- mean((test_data$amt_spent - predictions)^2)
r_squared <- cor(test_data$amt_spent, predictions)^2

print(paste("Mean Squared Error:", mse))
print(paste("R-squared:", r_squared))

```

Mean Squared Error (MSE): The MSE of the model on the testing set is 0.273, indicating that the model's predictions are generally close to the actual values of the target variable.


R-squared (R²): The R-squared value of the model is 0.75, suggesting that the model explains a substantial portion of the variability in the target variable, but there is still some

# 5.5 Conclusion

The linear regression analysis conducted on the marketing data yielded insightful findings regarding the relationship between the predictor variables and the amount spent on products. The obtained R-squared value of 0.7492 indicates that approximately 74.92% of the variability in the amount spent can be explained by the selected predictor variables. This suggests that the model captures a substantial portion of the underlying patterns and trends in the data.


Furthermore, the Mean Squared Error (MSE) value of 0.2738 suggests that the model's predictions are generally close to the actual values of the target variable. Although there is some variability remaining unexplained by the model, the relatively low MSE indicates that the model performs well in terms of predicting the amount spent on products.


In summary, while the linear regression model explains a significant portion of the variability in the amount spent and provides accurate predictions, there may still be additional factors influencing purchasing behavior that are not captured by the selected predictor variables. Further refinement of the model or consideration of additional variables may enhance its predictive accuracy and provide deeper insights into consumer behavior and marketing strategies.

# 6. Hypothesis Testing

# 6.1 Test 1

In our first testing let Null hypothesis be - Mean of the income of people who have opted for higher studies is same as to those who have not.


```{r,eval=TRUE,echo=FALSE}
graduation.data <- data$Income[data$Education=="Graduation"]

higherstudies.data.income <- data$Income[data$Education %in% c("Master", "PhD")]

t.test(graduation.data,higherstudies.data.income,var.equal=TRUE,conf.level=0.95)
#Null hypothesis - Mean of the income of people who have opted for higher studies is same as to those who have not

higherstudies.data <- data[data$Education %in% c("Graduation", "Master"),c(4,30)]
```

Based on the p-value (0.0764) being slightly higher than 0.05, we \*fail to reject the null hypothesis\* at the 95% confidence level. This implies that the observed difference in mean income (-1.773) between the graduation and higher studies groups might be due to chance and not a true population difference.





# 6.2 Test 2

In our second test our **Null hypothesis is- The proportion of customers who accept the offer is the same for both graduation and Master's degree holders.** This essentially suggests that education level (graduation vs. Master's) has no influence on a customer's decision to accept the offer.

**Alternative Hypothesis (H₁):** The proportion of customers who accept the offer differs between graduation and Master's degree holders.

```{r,eval=TRUE,echo=FALSE}
#Prop testing
table(higherstudies.data)
prop.test(c(964,309),c(1116,365),conf.level=0.95, correct=FALSE)
```

In this case, with a p-value of 0.411, we fail to reject the null hypothesis, indicating that the observed difference in offer acceptance proportions might be due to chance and not a true difference between the education groups.
